1
00:00:10,529 --> 00:00:14,527
ところで、すごく唐突なんですけれども、河野さんは

2
00:00:14,527 --> 00:00:17,568
ビル・ジョイという人物をご存じですか。

3
00:00:17,568 --> 00:00:19,993
はい。サン・マイクロシステムズの

4
00:00:19,993 --> 00:00:23,227
共同の設立者であって、その社の

5
00:00:23,227 --> 00:00:26,166
チーフサイエンティストでもあったかと思うんですが、

6
00:00:26,166 --> 00:00:30,202
情報技術という科学技術の最先端で多大な貢献をした

7
00:00:30,202 --> 00:00:33,005
インターネットのエジソンというふうに呼ばれるような

8
00:00:33,005 --> 00:00:35,781
技術者のことですね。

9
00:00:35,781 --> 00:00:37,564
そうですね。ビル・ジョイは、

10
00:00:37,564 --> 00:00:41,046
21世紀に急激に発展をすると、

11
00:00:41,046 --> 00:00:44,022
そういうふうに考えられる科学技術の分野、

12
00:00:44,022 --> 00:00:48,082
三つの領域なんですけれども、遺伝子工学ですね。

13
00:00:48,082 --> 00:00:51,913
それとナノテクノロジー、それとロボット工学。

14
00:00:51,913 --> 00:00:58,374
この三つの分野をそれぞれ頭文字を取ってGNRと、

15
00:00:58,374 --> 00:01:00,423
こういうふうに呼んでおりますけども、

16
00:01:00,423 --> 00:01:04,086
この三つの領域に注目をして、

17
00:01:04,086 --> 00:01:08,855
自分の専門の領域であったコンピューターの能力が

18
00:01:08,855 --> 00:01:12,680
飛躍的に向上するであろうということで、

19
00:01:12,680 --> 00:01:17,597
そうすると、これらの分野で人類を滅ぼしかねない、

20
00:01:17,597 --> 00:01:21,624
そういう技術が開発される可能性があるということを

21
00:01:21,624 --> 00:01:26,337
指摘したわけですね。遺伝子の工学の分野では、

22
00:01:26,337 --> 00:01:31,685
例えば、感染力を強化した、そういうインフルエンザや、

23
00:01:31,685 --> 00:01:38,948
あるいは特定の人種だけが感染するそういう人造病原体。

24
00:01:38,948 --> 00:01:41,743
こういったものを近い将来に

25
00:01:41,743 --> 00:01:43,844
作ることができるようになるだろうと、

26
00:01:43,844 --> 00:01:49,740
そういう予測をしました。さらに、20世紀を代表する

27
00:01:49,740 --> 00:01:55,052
兵器でありますけれども、核爆弾などが、

28
00:01:55,052 --> 00:02:00,423
これがもちろん大きな影響を人々や

29
00:02:00,423 --> 00:02:02,362
環境に与えるわけでありますけれども、

30
00:02:02,362 --> 00:02:04,401
それにしても一過性であろうと、

31
00:02:04,401 --> 00:02:08,012
それが使われたとしても。しかしながら、

32
00:02:08,012 --> 00:02:12,410
人造病原体っていうのは自己増殖機能っていうの、

33
00:02:12,410 --> 00:02:16,346
これを持たせることが可能になる、その可能性が高いと。

34
00:02:16,346 --> 00:02:22,095
そうすると、自己増殖してるわけですから、

35
00:02:22,095 --> 00:02:27,428
長期的でかつ広範な影響っていうのがあると考えれると、

36
00:02:27,428 --> 00:02:30,247
こういうふうに言ったわけです。

37
00:02:30,247 --> 00:02:33,370
彼は2000年当時でありますけれども、

38
00:02:33,370 --> 00:02:40,478
2030年までには当時に比べて100万倍の能力を持つ、

39
00:02:40,478 --> 00:02:43,429
そういうコンピューターが開発をされると、

40
00:02:43,429 --> 00:02:47,746
そういう予測をしたうえで、その能力を駆使すれば、

41
00:02:47,746 --> 00:02:51,223
ナノテクノロジーやロボット工学においても

42
00:02:51,223 --> 00:02:57,142
自己複製をする、そういう能力を持った、

43
00:02:57,142 --> 00:03:00,440
例えばナノスケールの非常に小さな

44
00:03:00,440 --> 00:03:04,301
人工物でありますとか、あるいは高度の知能と

45
00:03:04,301 --> 00:03:08,595
自己複製機能を持ったロボット。こういったものが

46
00:03:08,595 --> 00:03:12,119
開発されるだろうというふうに言ってるわけですね。

47
00:03:12,119 --> 00:03:16,054
もちろん、これらの技術が人類の福利に

48
00:03:16,054 --> 00:03:18,697
多大な貢献をするであろうこと。

49
00:03:18,697 --> 00:03:22,963
その可能性があるということは認めながらも、ジョイは

50
00:03:22,963 --> 00:03:28,973
潜在的な危険性に強い懸念を示しているわけです。

51
00:03:28,973 --> 00:03:31,258
しかも、これらの技術っていうのは、

52
00:03:31,258 --> 00:03:34,449
20世紀を特徴づけた、先ほど申し上げたような

53
00:03:34,449 --> 00:03:40,334
核兵器の開発のように、国を挙げた巨大プロジェクト、

54
00:03:40,334 --> 00:03:46,803
例えば核爆弾の開発のためにはこれ、

55
00:03:46,803 --> 00:03:48,985
マンハッタンプロジェクトと呼ばれますけれども、

56
00:03:48,985 --> 00:03:55,331
ここでは、延べ12万人の科学者、技術者が動員されて、

57
00:03:55,331 --> 00:03:58,242
30カ所以上の施設を作って、

58
00:03:58,242 --> 00:04:02,010
金額としては20億ドル以上を費やした。

59
00:04:02,010 --> 00:04:04,360
そういうふうにいわれておりますけども、

60
00:04:04,360 --> 00:04:09,191
そんな国家規模の開発をしなくても、

61
00:04:09,191 --> 00:04:15,086
21世紀の技術に関しては、GNRでありますけども、

62
00:04:15,086 --> 00:04:18,437
これに関しては、場合によっては個人が

63
00:04:18,437 --> 00:04:25,201
自分の自宅のガレージで、あるいは大学の一研究室で、

64
00:04:25,201 --> 00:04:27,653
パーソナルコンピューターを使って

65
00:04:27,653 --> 00:04:30,746
開発することができるようになる。

66
00:04:30,746 --> 00:04:36,969
かつては大型計算機を駆使して何日もかかってやった

67
00:04:36,969 --> 00:04:39,700
骨の折れる計算っていうのが、

68
00:04:39,700 --> 00:04:43,469
今では個人のコンピューターで処理をすることが

69
00:04:43,469 --> 00:04:48,461
可能でありますし、多くのスタッフが総出で

70
00:04:48,461 --> 00:04:51,908
数カ月もかかってやったような調査が今では

71
00:04:51,908 --> 00:04:54,869
インターネットを使って、あるいは人工知能の

72
00:04:54,869 --> 00:04:58,409
AIを使って簡単に調べることができると。

73
00:04:58,409 --> 00:05:04,159
このような環境の中で遺伝子工学、あるいは

74
00:05:04,159 --> 00:05:07,569
ナノテクノロジー、あるいはロボット工学。

75
00:05:07,569 --> 00:05:12,742
こういったものの開発は想像以上に簡単なことであると。

76
00:05:12,742 --> 00:05:17,174
IT技術、コンピューターを含みますけれども、

77
00:05:17,174 --> 00:05:20,472
この発展によって情報伝達のスピードと

78
00:05:20,472 --> 00:05:26,513
規模っていうのは急激に広がっていると。進んでいると。

79
00:05:26,513 --> 00:05:30,279
そうすると、そういったGNRに関しても

80
00:05:30,279 --> 00:05:35,209
ひとたび新しい知見が生まれると、その情報というのが、

81
00:05:35,209 --> 00:05:40,407
たとえ危険なものであったとしても、インターネットを

82
00:05:40,407 --> 00:05:45,782
通じて世界中に広がってしまうわけなので、

83
00:05:45,782 --> 00:05:48,707
そういった危険な情報の管理っていうのも

84
00:05:48,707 --> 00:05:55,874
難しいであろうと。悪意を持った犯罪者や

85
00:05:55,874 --> 00:05:58,763
テロリストたちにもこういう情報が

86
00:05:58,763 --> 00:06:02,695
共有されてしまう可能性が高いと。

87

87
00:06:02,695 --> 00:06:05,955
したがってと、ビル・ジョイは言うわけです。

88
00:06:05,955 --> 00:06:09,971
21世紀の人類は、彼はこういうふうに言ってますね。

89
00:06:09,971 --> 00:06:15,445
乗客全員がいつでも墜落ボタン、自爆ボタンを

90
00:06:15,445 --> 00:06:18,733
押せる状態で飛んでいるジェット機、

91
00:06:18,733 --> 00:06:21,246
これに乗っているようなものであると。

92
00:06:21,246 --> 00:06:27,195
これらの科学技術は個人すなわち1人の技術者、

93
00:06:27,195 --> 00:06:33,869
科学者が種としての人類全体の運命を

94
00:06:33,869 --> 00:06:36,330
決定する能力を持っていると。

95
00:06:36,330 --> 00:06:41,685
そういうことになるんだというわけですね。

96
00:06:41,685 --> 00:06:47,625
ですから、われわれは、こういう危険性を

97
00:06:47,625 --> 00:06:50,931
はらんでいる科学技術を扱うにあたっては

98
00:06:50,931 --> 00:06:54,893
リスクを十分評価しなきゃいけないし、

99
00:06:54,893 --> 00:06:59,731
新しい倫理規範というのを持たなきゃいけないと。

100
00:06:59,731 --> 00:07:03,604
こういうふうに彼は考えてるわけですね。

101
00:07:03,604 --> 00:07:06,569
ここにありますのが、スライドにありますのが、

102
00:07:06,569 --> 00:07:12,411
彼が提唱するところの21世紀の技術者が、あるいは

103
00:07:12,411 --> 00:07:17,448
科学者が持つべき倫理規範というものであります。

104
00:07:17,448 --> 00:07:22,888
ぜひ一度、ゆっくり見ていただきたいと思います。

105
00:07:22,888 --> 00:07:33,099
われわれ、そういう危険性が予測される場合には、

106
00:07:33,099 --> 00:07:37,790
研究開発というものを制限し、情報の公開にも

107
00:07:37,790 --> 00:07:42,009
配慮が必要であるとこういうふうに考えられるわけです。

108
00:07:42,009 --> 00:07:46,248
核兵器の出現というものを防げなかった

109
00:07:46,248 --> 00:07:50,086
20世紀の科学技術の専門家たち。

110
00:07:50,086 --> 00:07:53,859
この専門家たちの失敗を繰り返してはならないと。

111
00:07:53,859 --> 00:07:57,940
こういうふうにジョイは警告しているわけですね。

112
00:07:57,940 --> 00:08:01,508
危険な技術の創出や拡散を防ぐために、

113
00:08:01,508 --> 00:08:06,250
先ほど述べたような新しい倫理規範というのを

114
00:08:06,250 --> 00:08:11,598
提唱してるわけです。ビル・ジョイが示した

115
00:08:11,598 --> 00:08:13,172
未来像っていうのはあまりに

116
00:08:13,172 --> 00:08:15,388
悲観的ではありますけれども、

117
00:08:15,388 --> 00:08:19,507
科学技術と社会というマクロな関係を考えるうえで、

118
00:08:19,507 --> 00:08:27,198
こういう注意深い考察が必要であること、

119
00:08:27,198 --> 00:08:29,047
それが正しいことっていうのは、

120
00:08:29,047 --> 00:08:32,668
東日本大震災によっても、ある意味

121
00:08:32,668 --> 00:08:36,361
証明されてしまったということがいえると思います。

122
00:08:36,361 --> 00:08:38,597
新しい時代の技術者っていうのは、

123
00:08:38,597 --> 00:08:44,753
ジョイの批判を無視をして仕事を進めるというわけには

124
00:08:44,753 --> 00:08:46,544
もういかないんじゃないかなと、

125
00:08:46,544 --> 00:08:50,189
こういうふうに考えられます。でも、自分たちは

126
00:08:50,189 --> 00:08:52,916
技術をさらに発展させるんだと、

127
00:08:52,916 --> 00:08:58,110
それが技術者なわけですけれども、そういう人たちは

128
00:08:58,110 --> 00:09:03,511
ビル・ジョイの懸念というものを払拭できるだけの、

129
00:09:03,511 --> 00:09:07,799
そういう説明を自らできるように

130
00:09:07,799 --> 00:09:11,186
ならなきゃいけないんじゃないかと私は思います。

131
00:09:11,186 --> 00:09:13,737
ジョイの示した未来像っていうのが

132
00:09:13,737 --> 00:09:17,395
悲観的だというのであれば、楽観的でいられるような、

133
00:09:17,395 --> 00:09:21,144
そういう科学技術と社会の関係について

134
00:09:21,144 --> 00:09:24,829
クリエイティブな、創造的な設計というものを行って、

135
00:09:24,829 --> 00:09:27,648
その設計に従った世界を

136
00:09:27,648 --> 00:09:30,457
構築していかなければならないと。

137
00:09:30,457 --> 00:09:32,415
こういうふうに思います。

138
00:09:32,415 --> 00:09:34,706
私は、その鍵となるのが、

139
00:09:34,706 --> 00:09:37,725
何度も言っておりますけれども、よく生きること、

140
00:09:37,725 --> 00:09:40,975
well-beingに関しての科学的な研究と、

141
00:09:40,975 --> 00:09:45,530
そこから得られる成果というものを反映した

142
00:09:45,530 --> 00:09:51,022
技術者倫理であるというふうに考えています。

143
00:09:51,022 --> 00:09:55,614
既に議論しましたように、ポジティブ心理学の研究成果、

144
00:09:55,614 --> 00:09:59,170
すなわち人間は自分よりも大きな存在のために

145
00:09:59,170 --> 00:10:01,956
貢献することによってよく生きること、

146
00:10:01,956 --> 00:10:04,447
well-beingを高めることができるんだと。

147
00:10:04,447 --> 00:10:09,731
だからこそ、日常の業務の中で、PERMAですね、

148
00:10:09,731 --> 00:10:13,627
これに関する考察、これに基づく意思決定と

149
00:10:13,627 --> 00:10:20,327
行動を忘れることなく、定期的に俯瞰的な立場に立って、

150
00:10:20,327 --> 00:10:25,088
マクロエシックスの視点から自分が携わっている

151
00:10:25,088 --> 00:10:29,552
業務が公衆の福利に、well-beingにどのように

152
00:10:29,552 --> 00:10:33,257
貢献してるのか、これを確認することによって、

153
00:10:33,257 --> 00:10:35,675
自分自身の主観的な

154
00:10:35,675 --> 00:10:38,296
幸福度を高めることができるわけです。

155
00:10:38,296 --> 00:10:42,862
こういった互恵的な関係について、公衆との間で、

156
00:10:42,862 --> 00:10:45,620
一般の人たちとの間でちゃんと

157
00:10:45,620 --> 00:10:48,615
インフォームドコンセントというものを確立して

158
00:10:48,615 --> 00:10:50,995
コンセンサスを築き上げるために、

159
00:10:50,995 --> 00:10:56,857
技術者自らが自分の才能と知識、想像力、

160
00:10:56,857 --> 00:11:01,224
こういったものを最大限生かして、

161
00:11:01,224 --> 00:11:03,440
活用していかなければいけない、

162
00:11:03,440 --> 00:11:06,147
じゃないかなというふうに思います。

163
00:11:06,147 --> 00:11:09,666
このような時代だからこそ、科学技術を担う

164
00:11:09,666 --> 00:11:13,555
技術者の広い視野に立った

165
00:11:13,555 --> 00:11:16,758
マクロなレベルでの技術者倫理というものが

166
00:11:16,758 --> 00:11:19,865
期待されていると思います。

167
00:11:19,865 --> 00:11:22,021
報告書の中にもありましたけれども、

168
00:11:22,021 --> 00:11:24,884
原子力村といわれるわけですけども、

169
00:11:24,884 --> 00:11:28,844
原子力村の中に閉じこもっていてはいけないと

170
00:11:28,844 --> 00:11:32,455
報告書は書いてありますけれども、往々にして

171
00:11:32,455 --> 00:11:35,168
技術者の人たちは技術者村の中に

172
00:11:35,168 --> 00:11:38,270
入ってしまうわけでありますので、

173
00:11:38,270 --> 00:11:42,259
そういう技術者村にとらわれるのではなくて、

174
00:11:42,259 --> 00:11:47,362
積極的に社会との対話というのを推進していくこと。

175
00:11:47,362 --> 00:11:49,389
これは先ほどの学術会議の

176
00:11:49,389 --> 00:11:51,155
行動規範の中にもありましたけれども、

177
00:11:51,155 --> 00:11:55,269
それが新しい時代の技術者に求められている、

178
00:11:55,269 --> 00:11:57,470
そういう必須の能力といえるんじゃないかと、

179
00:11:57,470 --> 00:12:00,402
こういうふうに私は考えます。